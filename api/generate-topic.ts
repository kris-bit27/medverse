/**
 * generate-topic.ts â€” Multi-model content generation pipeline
 * 
 * Model strategy:
 *   fulltext, deep_dive â†’ Claude Opus 4.5 ($5/$25) â€” highest medical accuracy
 *   high_yield          â†’ Claude Sonnet 4 ($3/$15) â€” extracts from existing fulltext
 *   flashcards          â†’ Claude Haiku 4.5 ($1/$5) â€” simple Q&A generation
 *   mcq                 â†’ Claude Sonnet 4 ($3/$15) â€” needs clinical reasoning for distractors
 *   review              â†’ GPT-4o ($2.50/$10) â€” independent cross-model review
 */
import Anthropic from '@anthropic-ai/sdk';
import { getCached, setCache } from './cache.js';
import { supabaseAdmin } from './_supabaseAdmin.js';
import { z } from 'zod';

// â”€â”€â”€ Model Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const MODELS = {
  opus:   { id: 'claude-opus-4-20250514',   provider: 'anthropic', inputPer1M: 5,    outputPer1M: 25   },
  sonnet: { id: 'claude-sonnet-4-20250514',  provider: 'anthropic', inputPer1M: 3,    outputPer1M: 15   },
  haiku:  { id: 'claude-haiku-4-5-20251001', provider: 'anthropic', inputPer1M: 1,    outputPer1M: 5    },
  gpt4o:  { id: 'gpt-4o',                    provider: 'openai',    inputPer1M: 2.50, outputPer1M: 10   },
} as const;

type ModelKey = keyof typeof MODELS;

const MODE_MODEL_MAP: Record<string, ModelKey> = {
  fulltext:   'opus',
  deep_dive:  'opus',
  high_yield: 'sonnet',
  flashcards: 'haiku',
  mcq:        'sonnet',
  review:     'gpt4o',
};

const MODE_MAX_TOKENS: Record<string, number> = {
  fulltext:   8192,
  deep_dive:  8192,
  high_yield: 2048,
  flashcards: 2048,
  mcq:        2048,
  review:     4096,
};

// â”€â”€â”€ Input Validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const InputSchema = z.object({
  mode: z.enum([
    'fulltext', 'deep_dive', 'high_yield', 'flashcards', 'mcq', 'review',
    // Legacy aliases
    'topic_generate_fulltext_v2', 'topic_generate_high_yield', 'topic_generate_deep_dive'
  ]),
  context: z.object({
    specialty: z.string().max(100).optional(),
    okruh:     z.string().max(200).optional(),
    title:     z.string().min(1).max(300),
    full_text: z.string().max(80000).optional(),
    description: z.string().max(1000).optional(),
  }),
  model_override: z.enum(['opus', 'sonnet', 'haiku', 'gpt4o']).optional(),
});

// â”€â”€â”€ Normalize legacy mode names â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function normalizeMode(mode: string): string {
  const map: Record<string, string> = {
    'topic_generate_fulltext_v2': 'fulltext',
    'topic_generate_high_yield':  'high_yield',
    'topic_generate_deep_dive':   'deep_dive',
  };
  return map[mode] || mode;
}

// â”€â”€â”€ System Prompts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function getSystemPrompt(mode: string, ctx: any): string {
  const spec = ctx.specialty || 'medicÃ­nu';

  switch (mode) {
    case 'fulltext':
      return `Jsi senior klinickÃ½ lÃ©kaÅ™ a akademickÃ½ educator specializujÃ­cÃ­ se na ${spec}.

PRAVIDLA:
- Cituj zdroje: (Autor et al., Rok) nebo (Guidelines XY, 2024)
- Pokud si nejsi jistÃ½ faktem, oznaÄ jako "pÅ™ibliÅ¾nÄ›" nebo "typicky"
- Preferuj European/Czech guidelines (ESC, ÄŒLS JEP) nad americkÃ½mi kde relevantnÃ­
- NIKDY si nevymÃ½Å¡lej nÃ¡zvy studiÃ­ nebo cifry

VÃSTUPNÃ FORMÃT â€” vraÅ¥ POUZE validnÃ­ JSON:
{
  "full_text": "# TÃ©ma\\n\\n## 1. Ãšvod a definice\\n...celÃ½ markdown text...",
  "confidence": 0.85,
  "sources": ["ESC Guidelines 2024", "Harrison's Principles 21st ed."],
  "warnings": ["DÃ¡vkovÃ¡nÃ­ XY vyÅ¾aduje ovÄ›Å™enÃ­"]
}

STRUKTURA MARKDOWN (vÅ¡ech 7 sekcÃ­ POVINNÄš):
## 1. Ãšvod a definice
## 2. Epidemiologie
## 3. Etiopatogeneze
## 4. KlinickÃ½ obraz a diagnostika
## 5. Terapie
## 6. PrognÃ³za a komplikace
## 7. KlinickÃ© perly (pearl points)

ROZSAH: 3000-5000 slov. JAZYK: ÄŒeÅ¡tina, odbornÃ½ ale srozumitelnÃ½.
ÃšROVEÅ‡: Rezident/specialista pÅ™ipravujÃ­cÃ­ se k atestaci.`;

    case 'deep_dive':
      return `Jsi vÃ½zkumnÃ­k a klinickÃ½ specialista na ${spec}.

VytvoÅ™ DEEP DIVE obsah s pokroÄilÃ½mi znalostmi:
- MolekulÃ¡rnÃ­ mechanismy a patofyziologie na Ãºrovni receptorÅ¯
- AktuÃ¡lnÃ­ kontroverze a nedoÅ™eÅ¡enÃ© otÃ¡zky
- NovÃ© vÃ½zkumnÃ© smÄ›ry a experimentÃ¡lnÃ­ terapie
- PorovnÃ¡nÃ­ evropskÃ½ch vs americkÃ½ch guidelines
- KazuistickÃ© pÅ™Ã­klady pro obtÃ­Å¾nÃ© diferenciÃ¡lnÃ­ diagnÃ³zy

VÃSTUPNÃ FORMÃT â€” vraÅ¥ POUZE validnÃ­ JSON:
{
  "deep_dive": "# Deep Dive: TÃ©ma\\n\\n## PokroÄilÃ¡ patofyziologie\\n...",
  "confidence": 0.80,
  "sources": [],
  "warnings": [],
  "research_areas": ["oblast 1", "oblast 2"]
}

ROZSAH: 3000-5000 slov. JAZYK: ÄŒeÅ¡tina.`;

    case 'high_yield':
      return `Jsi medicÃ­nskÃ½ educator. Extrahuj HIGH-YIELD shrnutÃ­ z poskytnutÃ©ho fulltextu.

PRAVIDLA:
- Max 15 klÃ­ÄovÃ½ch bodÅ¯
- PouÅ¾Ã­vej formÃ¡tovÃ¡nÃ­: ðŸ”´ KRITICKÃ‰ / âš¡ HIGH-YIELD / ðŸ’Š TERAPIE / âš ï¸ CAVE
- KaÅ¾dÃ½ bod max 2 vÄ›ty
- ZamÄ›Å™ se na to co padÃ¡ u zkouÅ¡ek a atestacÃ­

VÃSTUPNÃ FORMÃT â€” vraÅ¥ POUZE validnÃ­ JSON:
{
  "high_yield": "# High-Yield: TÃ©ma\\n\\nðŸ”´ **KRITICKÃ‰:** ...\\nâš¡ **KEY FACT:** ...\\n...",
  "key_points": ["bod 1", "bod 2"],
  "confidence": 0.90
}`;

    case 'flashcards':
      return `Generuj flashcards (kartiÄky) z medicÃ­nskÃ©ho textu.

PRAVIDLA:
- Generuj 10 kartiÄek z poskytnutÃ©ho obsahu
- Mix typÅ¯: definice, mechanismus, diagnostika, terapie, diferenciÃ¡lnÃ­ diagnÃ³za
- OtÃ¡zky struÄnÃ© a jasnÃ©, odpovÄ›di max 3 vÄ›ty
- ObtÃ­Å¾nost 1-3 (1=zÃ¡kladnÃ­, 2=pokroÄilÃ½, 3=atestaÄnÃ­)

VÃSTUPNÃ FORMÃT â€” vraÅ¥ POUZE validnÃ­ JSON:
{
  "flashcards": [
    {"question": "...", "answer": "...", "difficulty": 2, "tags": ["diagnostika"]},
    ...
  ],
  "confidence": 0.85
}`;

    case 'mcq':
      return `Generuj MCQ (multiple-choice questions) z medicÃ­nskÃ©ho textu.

PRAVIDLA:
- Generuj 5 otÃ¡zek s 4-5 moÅ¾nostmi (A-E)
- Jedna sprÃ¡vnÃ¡ odpovÄ›Ä, ostatnÃ­ jsou plausible distraktory
- Ke kaÅ¾dÃ© otÃ¡zce vysvÄ›tlenÃ­ proÄ je sprÃ¡vnÃ¡ a proÄ ostatnÃ­ ne
- Mix obtÃ­Å¾nostÃ­

VÃSTUPNÃ FORMÃT â€” vraÅ¥ POUZE validnÃ­ JSON:
{
  "questions": [
    {
      "question_text": "...",
      "options": {"A": "...", "B": "...", "C": "...", "D": "..."},
      "correct_answer": "B",
      "explanation": "...",
      "difficulty": 2,
      "tags": ["diagnostika"]
    }
  ],
  "confidence": 0.85
}`;

    case 'review':
      return `You are an independent medical content reviewer. You are reviewing AI-generated educational content.

Analyze the provided content for:
1. SAFETY: incorrect dosages, dangerous advice, missing contraindications (score 0-100)
2. COMPLETENESS: missing standard sections for the topic (score 0-100)
3. ACCURACY: factual errors, outdated guidelines, unsupported claims (score 0-100)
4. EDUCATIONAL VALUE: clarity, structure, appropriate depth (score 0-100)

Return ONLY valid JSON:
{
  "approved": boolean,
  "confidence": number (0-1),
  "safety_score": number,
  "completeness_score": number,
  "accuracy_score": number,
  "educational_score": number,
  "overall_score": number,
  "issues": [{"severity": "high|medium|low", "category": "dosage|safety|accuracy|completeness|formatting", "description": "...", "suggestion": "..."}],
  "strengths": ["..."],
  "missing_sections": ["..."]
}

approved=true ONLY if safety_score >= 80 AND no high-severity issues.
Language: Czech for descriptions, but JSON keys in English.`;

    default:
      return `Jsi medicÃ­nskÃ½ AI asistent. OdpovÃ­dej Äesky, strukturovanÄ›.`;
  }
}

function getUserPrompt(mode: string, ctx: any): string {
  switch (mode) {
    case 'fulltext':
      return `VytvoÅ™ kompletnÃ­ atestaÄnÃ­ fulltext pro:
**Obor:** ${ctx.specialty || 'MedicÃ­na'}
**Okruh:** ${ctx.okruh || ''}
**TÃ©ma:** ${ctx.title}
${ctx.description ? `**Popis:** ${ctx.description}` : ''}

Adaptuj na ÄŒR/EU kontext. Preferuj EMA/ESC guidelines.`;

    case 'deep_dive':
      return `VytvoÅ™ Deep Dive pro:
**TÃ©ma:** ${ctx.title}
**Obor:** ${ctx.specialty || ''}
${ctx.full_text ? `\n**ReferenÄnÃ­ fulltext (zkrÃ¡cenÃ½):**\n${ctx.full_text.substring(0, 3000)}...` : ''}`;

    case 'high_yield':
      if (!ctx.full_text) return `VytvoÅ™ high-yield shrnutÃ­ pro: ${ctx.title}`;
      return `Extrahuj HIGH-YIELD body z tohoto fulltextu:

**TÃ©ma:** ${ctx.title}

**FULLTEXT:**
${ctx.full_text.substring(0, 15000)}`;

    case 'flashcards':
      return `Vygeneruj 10 flashcards z:
**TÃ©ma:** ${ctx.title}
${ctx.full_text ? `\n**OBSAH:**\n${ctx.full_text.substring(0, 10000)}` : ''}`;

    case 'mcq':
      return `Vygeneruj 5 MCQ otÃ¡zek z:
**TÃ©ma:** ${ctx.title}
${ctx.full_text ? `\n**OBSAH:**\n${ctx.full_text.substring(0, 10000)}` : ''}`;

    case 'review':
      return `Review this medical educational content:
**Topic:** ${ctx.title}
**Specialty:** ${ctx.specialty || 'General'}

**CONTENT TO REVIEW:**
${ctx.full_text || 'No content provided'}`;

    default:
      return ctx.title;
  }
}

// â”€â”€â”€ API Clients â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function getAnthropicClient(): Anthropic {
  const key = process.env.ANTHROPIC_API_KEY || process.env.VITE_ANTHROPIC_API_KEY;
  if (!key) throw new Error('Missing ANTHROPIC_API_KEY');
  return new Anthropic({ apiKey: key });
}

async function callAnthropic(modelKey: ModelKey, system: string, user: string, maxTokens: number) {
  const model = MODELS[modelKey];
  const client = getAnthropicClient();
  
  const response = await client.messages.create({
    model: model.id,
    max_tokens: maxTokens,
    temperature: 0.3,
    system,
    messages: [{ role: 'user', content: user }],
  });

  const text = response.content
    .filter((b: any) => b.type === 'text')
    .map((b: any) => b.text)
    .join('');

  const usage = response.usage || { input_tokens: 0, output_tokens: 0 };
  const cost = {
    input:  (usage.input_tokens  / 1_000_000) * model.inputPer1M,
    output: (usage.output_tokens / 1_000_000) * model.outputPer1M,
    total:  0,
  };
  cost.total = cost.input + cost.output;

  return { text, usage, cost, provider: 'anthropic', modelId: model.id };
}

async function callOpenAI(system: string, user: string, maxTokens: number) {
  const key = process.env.OPENAI_API_KEY;
  if (!key) throw new Error('Missing OPENAI_API_KEY â€” needed for cross-model review');

  const model = MODELS.gpt4o;
  
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${key}`,
    },
    body: JSON.stringify({
      model: model.id,
      max_tokens: maxTokens,
      temperature: 0.3,
      messages: [
        { role: 'system', content: system },
        { role: 'user', content: user },
      ],
    }),
  });

  if (!response.ok) {
    const err = await response.text();
    throw new Error(`OpenAI API error (${response.status}): ${err}`);
  }

  const data = await response.json();
  const text = data.choices?.[0]?.message?.content || '';
  const usage = data.usage || { prompt_tokens: 0, completion_tokens: 0 };
  
  const cost = {
    input:  (usage.prompt_tokens     / 1_000_000) * model.inputPer1M,
    output: (usage.completion_tokens  / 1_000_000) * model.outputPer1M,
    total:  0,
  };
  cost.total = cost.input + cost.output;

  return { 
    text, 
    usage: { input_tokens: usage.prompt_tokens, output_tokens: usage.completion_tokens },
    cost, 
    provider: 'openai', 
    modelId: model.id 
  };
}

// â”€â”€â”€ JSON Parser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function tryParseJson(raw: string): any {
  const cleaned = raw.replace(/```json\n?|\n?```/g, '').trim();
  try { return JSON.parse(cleaned); } catch {}
  // Try extracting JSON block
  const first = cleaned.indexOf('{');
  const last = cleaned.lastIndexOf('}');
  if (first !== -1 && last > first) {
    try { return JSON.parse(cleaned.slice(first, last + 1)); } catch {}
  }
  return null;
}

function normalizeNewlines(val?: string | null): string | undefined {
  if (!val || typeof val !== 'string') return undefined;
  return val.replace(/\\n/g, '\n').replace(/\\t/g, '\t');
}

// â”€â”€â”€ Track AI Usage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function trackUsage(userId: string | null, model: string, tokens: number, cost: number, mode: string) {
  try {
    if (!userId) return;
    await supabaseAdmin.from('user_ai_usage').insert({
      user_id: userId,
      model,
      tokens_used: tokens,
      cost,
      mode: `topic_generate_${mode}`,
    });
  } catch (e) {
    console.error('[Usage tracking error]', e);
  }
}

// â”€â”€â”€ CORS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const ALLOWED_ORIGINS = [
  'https://medverse-gilt.vercel.app',
  'https://medverse.com',
  'https://www.medverse.com',
  'http://localhost:3000',
  'http://localhost:5173',
];

// â”€â”€â”€ Main Handler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export default async function handler(req: any, res: any) {
  // CORS
  const origin = req.headers.origin;
  if (ALLOWED_ORIGINS.includes(origin)) {
    res.setHeader('Access-Control-Allow-Origin', origin);
    res.setHeader('Access-Control-Allow-Credentials', 'true');
  }
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization');
  if (req.method === 'OPTIONS') return res.status(200).end();
  if (req.method !== 'POST') return res.status(405).json({ error: 'Method not allowed' });

  const startTime = Date.now();

  try {
    // Validate
    const parsed = InputSchema.safeParse(req.body);
    if (!parsed.success) {
      return res.status(400).json({ error: 'Invalid input', details: parsed.error.errors });
    }

    const mode = normalizeMode(parsed.data.mode);
    const ctx = parsed.data.context;
    const modelOverride = parsed.data.model_override;

    // Resolve model
    const modelKey: ModelKey = modelOverride || MODE_MODEL_MAP[mode] || 'sonnet';
    const modelCfg = MODELS[modelKey];

    console.log(`[generate-topic] mode=${mode} model=${modelKey} (${modelCfg.id}) title="${ctx.title}"`);

    // Check cache
    const cacheContext = { ...ctx, _model: modelKey };
    const cached = await getCached(mode, cacheContext);
    if (cached) {
      console.log('[generate-topic] Cache HIT');
      return res.status(200).json({ ...cached.response, _cache: cached.metadata });
    }

    // Build prompts
    const systemPrompt = getSystemPrompt(mode, ctx);
    const userPrompt = getUserPrompt(mode, ctx);
    const maxTokens = MODE_MAX_TOKENS[mode] || 4096;

    // Call appropriate provider
    let result;
    if (modelCfg.provider === 'openai') {
      result = await callOpenAI(systemPrompt, userPrompt, maxTokens);
    } else {
      result = await callAnthropic(modelKey, systemPrompt, userPrompt, maxTokens);
    }

    // Parse response
    let output = tryParseJson(result.text);
    if (!output) {
      output = { text: result.text };
    }

    // Normalize markdown newlines
    for (const key of ['full_text', 'high_yield', 'deep_dive']) {
      if (output[key]) output[key] = normalizeNewlines(output[key]);
    }

    // Attach metadata
    output.sources = output.sources || [];
    output.warnings = output.warnings || [];
    output.metadata = {
      provider: result.provider,
      model: result.modelId,
      modelKey,
      tokensUsed: result.usage,
      cost: {
        input:  result.cost.input.toFixed(4),
        output: result.cost.output.toFixed(4),
        total:  result.cost.total.toFixed(4),
      },
      generatedAt: new Date().toISOString(),
      durationMs: Date.now() - startTime,
    };

    // Track usage
    const authHeader = req.headers.authorization;
    let userId: string | null = null;
    if (authHeader?.startsWith('Bearer ')) {
      try {
        const { data } = await supabaseAdmin.auth.getUser(authHeader.replace('Bearer ', ''));
        userId = data?.user?.id || null;
      } catch {}
    }
    
    const totalTokens = (result.usage.input_tokens || 0) + (result.usage.output_tokens || 0);
    await trackUsage(userId, result.modelId, totalTokens, result.cost.total, mode);

    // Cache
    await setCache(mode, cacheContext, output);

    console.log(`[generate-topic] âœ… ${mode} done in ${Date.now() - startTime}ms, cost=$${result.cost.total.toFixed(4)}`);

    return res.status(200).json(output);

  } catch (error: any) {
    const errorId = Math.random().toString(36).substring(7);
    console.error(`[generate-topic ERROR ${errorId}]`, error.message, error.stack?.substring(0, 300));

    return res.status(500).json({
      error: 'Generation failed',
      errorId,
      message: process.env.NODE_ENV === 'development' ? error.message : 'Please try again or contact support.',
    });
  }
}
